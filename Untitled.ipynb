{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import re, string\n",
    "import sys\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import mpl_toolkits\n",
    "\n",
    "from subprocess import check_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"data.csv\" , encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>purchased_variant_id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>advantages</th>\n",
       "      <th>disadvantages</th>\n",
       "      <th>created_at</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318109559</td>\n",
       "      <td>19118836</td>\n",
       "      <td>37083487</td>\n",
       "      <td>57919781.0</td>\n",
       "      <td>عالی</td>\n",
       "      <td>عالی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-04 21:19:04</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231829415</td>\n",
       "      <td>1385206</td>\n",
       "      <td>102574956</td>\n",
       "      <td>49696397.0</td>\n",
       "      <td>محافظ دسته</td>\n",
       "      <td>این که قبل عید سی تومن بود الان زده شصت تومن ا...</td>\n",
       "      <td>[\\\"خوش دست و زیبا\\\"]</td>\n",
       "      <td>[\\\"قیمت بالا\\\"]</td>\n",
       "      <td>2019-04-04 21:18:08</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381611181</td>\n",
       "      <td>14182432</td>\n",
       "      <td>307517</td>\n",
       "      <td>47989652.0</td>\n",
       "      <td>نوع جلد و نظر درباره کتاب</td>\n",
       "      <td>جلد کتاب سخت بود و در سایت نوشته نشده بود.\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\\"جلد سخت کتاب\\\\r\\\",\\\"قیمت کمی بالاتر از انتظ...</td>\n",
       "      <td>2019-04-04 21:18:00</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93129005</td>\n",
       "      <td>15816336</td>\n",
       "      <td>130110910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>خوب بود</td>\n",
       "      <td>خیلی خوب بود ولی بنظرم نسبت به رنگارنگ قیمت تف...</td>\n",
       "      <td>[\\\"راحتی و بیس مناسب\\\"]</td>\n",
       "      <td>[\\\"گران بود نسبت به رنگ ها \\\"]</td>\n",
       "      <td>2019-04-04 21:17:56</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337837724</td>\n",
       "      <td>17810598</td>\n",
       "      <td>143426093</td>\n",
       "      <td>30317751.0</td>\n",
       "      <td>خوب نیست نخرید</td>\n",
       "      <td>برا آقایون اصلا خوب نیست بعد از سه هفته استفاد...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-04 21:17:38</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  product_id    user_id  purchased_variant_id  \\\n",
       "0  318109559    19118836   37083487            57919781.0   \n",
       "1  231829415     1385206  102574956            49696397.0   \n",
       "2  381611181    14182432     307517            47989652.0   \n",
       "3   93129005    15816336  130110910                   NaN   \n",
       "4  337837724    17810598  143426093            30317751.0   \n",
       "\n",
       "                       title  \\\n",
       "0                       عالی   \n",
       "1                 محافظ دسته   \n",
       "2  نوع جلد و نظر درباره کتاب   \n",
       "3                    خوب بود   \n",
       "4             خوب نیست نخرید   \n",
       "\n",
       "                                             comment               advantages  \\\n",
       "0                                               عالی                      NaN   \n",
       "1  این که قبل عید سی تومن بود الان زده شصت تومن ا...     [\\\"خوش دست و زیبا\\\"]   \n",
       "2  جلد کتاب سخت بود و در سایت نوشته نشده بود.\\r\\n...                      NaN   \n",
       "3  خیلی خوب بود ولی بنظرم نسبت به رنگارنگ قیمت تف...  [\\\"راحتی و بیس مناسب\\\"]   \n",
       "4  برا آقایون اصلا خوب نیست بعد از سه هفته استفاد...                      NaN   \n",
       "\n",
       "                                       disadvantages           created_at  \\\n",
       "0                                                NaN  2019-04-04 21:19:04   \n",
       "1                                    [\\\"قیمت بالا\\\"]  2019-04-04 21:18:08   \n",
       "2  [\\\"جلد سخت کتاب\\\\r\\\",\\\"قیمت کمی بالاتر از انتظ...  2019-04-04 21:18:00   \n",
       "3                     [\\\"گران بود نسبت به رنگ ها \\\"]  2019-04-04 21:17:56   \n",
       "4                                                NaN  2019-04-04 21:17:38   \n",
       "\n",
       "  verification_status  \n",
       "0            verified  \n",
       "1            rejected  \n",
       "2            verified  \n",
       "3            verified  \n",
       "4            rejected  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataC = comments.comment\n",
    "dataA = comments.advantages\n",
    "dataD = comments.disadvantages\n",
    "label = comments.verification_status\n",
    "for i in label:\n",
    "    if (i == 'verified'):\n",
    "        i = 1\n",
    "    else:\n",
    "        i = 0\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "dataC.head()\n",
    "print(type(dataC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        NaN\n",
       "1       [\\\"خوش دست و زیبا\\\"]\n",
       "2                        NaN\n",
       "3    [\\\"راحتی و بیس مناسب\\\"]\n",
       "4                        NaN\n",
       "Name: advantages, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_reviews = len(comments[comments[\"useful\"]>0])\n",
    "cool_reviews = len(comments[comments[\"cool\"]>0])\n",
    "funny_reviews = len(comments[comments[\"funny\"]>0])\n",
    "\n",
    "total_reviews = len(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5899999"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cm in dataC:\n",
    "    cm = cm.split()\n",
    "\n",
    "\n",
    "#split_c = dataC.split();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Counter' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5cb094202f74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# most_common() produces k frequently encountered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# input values and their respective counts.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmost_occur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Counter' object is not callable"
     ]
    }
   ],
   "source": [
    "Counter = Counter(dataC) \n",
    "  \n",
    "# most_common() produces k frequently encountered \n",
    "# input values and their respective counts. \n",
    "most_occur = Counter.most_common(4) \n",
    "  \n",
    "print(most_occur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    \"\"\"Convert string to lowercase and split into words (ignoring\n",
    "    punctuation), returning list of words.\n",
    "    \"\"\"\n",
    "    word_list = re.findall(r'\\w+')\n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    return filtered_words\n",
    "\n",
    "def count_ngrams(lines, min_length=2, max_length=4):\n",
    "    \"\"\"Iterate through given lines iterator (file object or list of\n",
    "    lines) and return n-gram frequencies. The return value is a dict\n",
    "    mapping the length of the n-gram to a collections.Counter\n",
    "    object of n-gram tuple and number of times that n-gram occurred.\n",
    "    Returned dict includes n-grams of length min_length to max_length.\n",
    "    \"\"\"\n",
    "    lengths = range(min_length, max_length + 1)\n",
    "    ngrams = {length: collections.Counter() for length in lengths}\n",
    "    queue = collections.deque(maxlen=max_length)\n",
    "\n",
    "    # Helper function to add n-grams at start of current queue to dict\n",
    "    def add_queue():\n",
    "        current = tuple(queue)\n",
    "        for length in lengths:\n",
    "            if len(current) >= length:\n",
    "                ngrams[length][current[:length]] += 1\n",
    "\n",
    "    # Loop through all lines and words and add n-grams to dict\n",
    "    for line in lines:\n",
    "        for word in tokenize(line):\n",
    "            queue.append(word)\n",
    "            if len(queue) >= max_length:\n",
    "                add_queue()\n",
    "\n",
    "    # Make sure we get the n-grams at the tail end of the queue\n",
    "    while len(queue) > min_length:\n",
    "        queue.popleft()\n",
    "        add_queue()\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "def print_most_frequent(ngrams, num=10):\n",
    "    \"\"\"Print num most common n-grams of each length in n-grams dict.\"\"\"\n",
    "    for n in sorted(ngrams):\n",
    "        print('----- {} most common {}-word phrase -----'.format(num, n))\n",
    "        for gram, count in ngrams[n].most_common(num):\n",
    "            print('{0}: {1}'.format(' '.join(gram), count))\n",
    "        print('')\n",
    "\n",
    "def print_word_cloud(ngrams, num=5):\n",
    "    \"\"\"Print word cloud image plot \"\"\"\n",
    "    words = []\n",
    "    for n in sorted(ngrams):\n",
    "        for gram, count in ngrams[n].most_common(num):\n",
    "            s = ' '.join(gram)\n",
    "            words.append(s)\n",
    "            \n",
    "    cloud = WordCloud(width=1440, height= 1080,max_words= 200).generate(' '.join(words))\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
